{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4f2e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class BatteryLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate=0.2):\n",
    "        super(BatteryLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                           batch_first=True, dropout=dropout_rate)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size // 4, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM forward pass\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        output = self.fc_layers(context_vector)\n",
    "        return output\n",
    "\n",
    "class BatteryDataProcessor:\n",
    "    def __init__(self, sequence_length=10):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.scaler = StandardScaler()\n",
    "        self.capacity_scaler = StandardScaler()\n",
    "\n",
    "    def load_battery_data(self, file_path):\n",
    "        \"\"\"Load MATLAB battery data file\"\"\"\n",
    "        try:\n",
    "            data = scipy.io.loadmat(file_path)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def explore_mat_structure(self, data, file_name):\n",
    "        \"\"\"Explore the structure of .mat file\"\"\"\n",
    "        print(f\"\\n=== Exploring {file_name} ===\")\n",
    "        for key in data.keys():\n",
    "            if not key.startswith('__'):\n",
    "                value = data[key]\n",
    "                print(f\"Key: {key}\")\n",
    "                print(f\"  Type: {type(value)}\")\n",
    "                if hasattr(value, 'shape'):\n",
    "                    print(f\"  Shape: {value.shape}\")\n",
    "                if hasattr(value, 'dtype'):\n",
    "                    print(f\"  Dtype: {value.dtype}\")\n",
    "\n",
    "                # If it's a structured array, show the fields\n",
    "                if hasattr(value, 'dtype') and value.dtype.names:\n",
    "                    print(f\"  Fields: {value.dtype.names}\")\n",
    "                    # Show first element structure if available\n",
    "                    if len(value) > 0:\n",
    "                        first_elem = value[0,0] if value.ndim == 2 else value[0]\n",
    "                        if hasattr(first_elem, 'dtype') and first_elem.dtype.names:\n",
    "                            print(f\"  First element fields: {first_elem.dtype.names}\")\n",
    "\n",
    "    def extract_features_from_arc_data(self, data, battery_id):\n",
    "        \"\"\"Extract features from NASA ARC battery dataset structure\"\"\"\n",
    "        cycles = []\n",
    "\n",
    "        # NASA ARC dataset typically has 'cycle' as the main structure\n",
    "        if 'cycle' in data:\n",
    "            cycle_data = data['cycle']\n",
    "            print(f\"Processing {battery_id} - Cycles: {cycle_data.shape}\")\n",
    "\n",
    "            for cycle_num in range(cycle_data.shape[1]):\n",
    "                cycle = cycle_data[0, cycle_num]\n",
    "\n",
    "                # Check if cycle has the expected structure\n",
    "                if hasattr(cycle, 'dtype') and cycle.dtype.names:\n",
    "                    if 'data' in cycle.dtype.names and 'type' in cycle.dtype.names:\n",
    "                        cycle_type = cycle['type'][0]\n",
    "                        # Only process discharge cycles\n",
    "                        if cycle_type == 'discharge':\n",
    "                            cycle_info = cycle['data'][0, 0]\n",
    "\n",
    "                            if hasattr(cycle_info, 'dtype') and cycle_info.dtype.names:\n",
    "                                # Extract available measurements\n",
    "                                features = {'cycle': cycle_num + 1, 'battery_id': battery_id}\n",
    "\n",
    "                                # Common measurements in NASA dataset\n",
    "                                possible_fields = [\n",
    "                                    'Voltage_measured', 'Current_measured',\n",
    "                                    'Temperature_measured', 'Capacity',\n",
    "                                    'Current_load', 'Voltage_load', 'Time'\n",
    "                                ]\n",
    "\n",
    "                                for field in possible_fields:\n",
    "                                    if field in cycle_info.dtype.names:\n",
    "                                        field_data = cycle_info[field][0, 0]\n",
    "                                        if field_data.size > 0:\n",
    "                                            if field == 'Capacity':\n",
    "                                                features[field.lower()] = float(field_data[0, 0])\n",
    "                                            else:\n",
    "                                                # Calculate statistics for time-series data\n",
    "                                                features[f'{field.lower()}_mean'] = float(np.mean(field_data))\n",
    "                                                features[f'{field.lower()}_std'] = float(np.std(field_data))\n",
    "                                                features[f'{field.lower()}_max'] = float(np.max(field_data))\n",
    "                                                features[f'{field.lower()}_min'] = float(np.min(field_data))\n",
    "\n",
    "                                # Only add if we have capacity data\n",
    "                                if 'capacity' in features:\n",
    "                                    cycles.append(features)\n",
    "\n",
    "        return pd.DataFrame(cycles)\n",
    "\n",
    "    def extract_features_simple(self, data, battery_id):\n",
    "        \"\"\"Simplified feature extraction for different .mat structures\"\"\"\n",
    "        cycles = []\n",
    "\n",
    "        # Try to find capacity data directly\n",
    "        for key in data.keys():\n",
    "            if not key.startswith('__'):\n",
    "                value = data[key]\n",
    "                print(f\"Checking key {key} with shape {value.shape if hasattr(value, 'shape') else 'N/A'}\")\n",
    "\n",
    "                # Look for capacity-like data\n",
    "                if 'capacity' in key.lower() and hasattr(value, 'shape'):\n",
    "                    if value.size > 1:\n",
    "                        # Assume it's a time series of capacities\n",
    "                        for i, capacity in enumerate(value.flatten()):\n",
    "                            cycles.append({\n",
    "                                'cycle': i + 1,\n",
    "                                'battery_id': battery_id,\n",
    "                                'capacity': float(capacity)\n",
    "                            })\n",
    "                    else:\n",
    "                        cycles.append({\n",
    "                            'cycle': 1,\n",
    "                            'battery_id': battery_id,\n",
    "                            'capacity': float(value)\n",
    "                        })\n",
    "\n",
    "        return pd.DataFrame(cycles)\n",
    "\n",
    "    def load_all_battery_files(self, data_directory):\n",
    "        \"\"\"Load all battery .mat files from directory\"\"\"\n",
    "        data_path = Path(data_directory)\n",
    "        all_data = {}\n",
    "\n",
    "        # Find all .mat files\n",
    "        mat_files = list(data_path.glob('*.mat'))\n",
    "        print(f\"Found {len(mat_files)} .mat files:\")\n",
    "\n",
    "        for mat_file in mat_files:\n",
    "            print(f\"  - {mat_file.name}\")\n",
    "            battery_id = mat_file.stem\n",
    "            data = self.load_battery_data(mat_file)\n",
    "\n",
    "            if data is not None:\n",
    "                # Explore the structure first\n",
    "                self.explore_mat_structure(data, battery_id)\n",
    "\n",
    "                # Try different extraction methods\n",
    "                df = self.extract_features_from_arc_data(data, battery_id)\n",
    "\n",
    "                if df.empty:\n",
    "                    df = self.extract_features_simple(data, battery_id)\n",
    "\n",
    "                if not df.empty:\n",
    "                    all_data[battery_id] = df\n",
    "                    print(f\"  Extracted {len(df)} cycles\")\n",
    "                else:\n",
    "                    print(f\"  No cycles extracted from {battery_id}\")\n",
    "\n",
    "        return all_data\n",
    "\n",
    "    def combine_battery_data(self, all_data):\n",
    "        \"\"\"Combine data from all batteries into single DataFrame\"\"\"\n",
    "        combined_df = pd.DataFrame()\n",
    "\n",
    "        for battery_id, df in all_data.items():\n",
    "            if not df.empty:\n",
    "                df['battery_id'] = battery_id\n",
    "                combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "        print(f\"Combined data shape: {combined_df.shape}\")\n",
    "        return combined_df\n",
    "\n",
    "    def create_sequences(self, data, target_col='capacity'):\n",
    "        \"\"\"Create sequences for LSTM training\"\"\"\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        sequence_info = []  # Store information about each sequence\n",
    "\n",
    "        # Group by battery_id and create sequences for each battery\n",
    "        for battery_id in data['battery_id'].unique():\n",
    "            battery_data = data[data['battery_id'] == battery_id].sort_values('cycle')\n",
    "\n",
    "            # Select feature columns (exclude cycle and battery_id)\n",
    "            feature_cols = [col for col in battery_data.columns\n",
    "                           if col not in ['cycle', 'battery_id', target_col]\n",
    "                           and pd.api.types.is_numeric_dtype(battery_data[col])]\n",
    "\n",
    "            if len(feature_cols) == 0:\n",
    "                # If no features, use cycle number as feature\n",
    "                feature_cols = ['cycle']\n",
    "                battery_data_features = battery_data[feature_cols].copy()\n",
    "            else:\n",
    "                battery_data_features = battery_data[feature_cols].copy()\n",
    "\n",
    "            target_values = battery_data[target_col].values\n",
    "\n",
    "            # Handle NaN values\n",
    "            battery_data_features = battery_data_features.fillna(battery_data_features.mean())\n",
    "            target_values = np.nan_to_num(target_values, nan=np.nanmean(target_values))\n",
    "\n",
    "            # Scale features and targets\n",
    "            if len(sequences) == 0:  # First battery, fit scalers\n",
    "                scaled_features = self.scaler.fit_transform(battery_data_features)\n",
    "                scaled_targets = self.capacity_scaler.fit_transform(target_values.reshape(-1, 1)).flatten()\n",
    "            else:  # Subsequent batteries, transform only\n",
    "                scaled_features = self.scaler.transform(battery_data_features)\n",
    "                scaled_targets = self.capacity_scaler.transform(target_values.reshape(-1, 1)).flatten()\n",
    "\n",
    "            # Create sequences for this battery\n",
    "            for i in range(len(battery_data) - self.sequence_length):\n",
    "                seq = scaled_features[i:(i + self.sequence_length)]\n",
    "                target = scaled_targets[i + self.sequence_length]\n",
    "                sequences.append(seq)\n",
    "                targets.append(target)\n",
    "                \n",
    "                # Store sequence information for later reference\n",
    "                sequence_info.append({\n",
    "                    'battery_id': battery_id,\n",
    "                    'actual_cycle': battery_data.iloc[i + self.sequence_length]['cycle'],\n",
    "                    'actual_capacity': battery_data.iloc[i + self.sequence_length][target_col]\n",
    "                })\n",
    "\n",
    "        return np.array(sequences), np.array(targets), sequence_info\n",
    "\n",
    "    def prepare_synthetic_data(self, num_cycles=500):\n",
    "        \"\"\"Generate synthetic battery data for demonstration\"\"\"\n",
    "        cycles = []\n",
    "\n",
    "        # Synthetic battery degradation pattern\n",
    "        for i in range(num_cycles):\n",
    "            # Capacity degradation (typical pattern)\n",
    "            base_capacity = 2.0\n",
    "            degradation = 0.001 * i + 0.0001 * i**2\n",
    "            noise = np.random.normal(0, 0.01)\n",
    "            capacity = base_capacity - degradation + noise\n",
    "\n",
    "            # Other features with realistic patterns\n",
    "            avg_voltage = 3.7 - 0.0005 * i + np.random.normal(0, 0.02)\n",
    "            avg_current = 1.5 + np.random.normal(0, 0.1)\n",
    "            max_voltage = 4.2 - 0.0002 * i\n",
    "            min_voltage = 3.0 + 0.0001 * i\n",
    "            avg_temperature = 25 + 0.01 * i + np.random.normal(0, 0.5)\n",
    "\n",
    "            cycles.append({\n",
    "                'cycle': i + 1,\n",
    "                'capacity': max(0.5, capacity),  # Prevent negative capacity\n",
    "                'avg_voltage': avg_voltage,\n",
    "                'avg_current': avg_current,\n",
    "                'max_voltage': max_voltage,\n",
    "                'min_voltage': min_voltage,\n",
    "                'avg_temperature': avg_temperature,\n",
    "                'battery_id': 'synthetic'\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(cycles)\n",
    "\n",
    "class BatteryTrainer:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def train(self, train_loader, val_loader, num_epochs, learning_rate):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation phase\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
    "                    outputs = self.model(batch_X)\n",
    "                    loss = criterion(outputs.squeeze(), batch_y)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "            self.train_losses.append(avg_train_loss)\n",
    "            self.val_losses.append(avg_val_loss)\n",
    "\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        plt.plot(self.val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training History')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "def evaluate_model(model, test_loader, data_processor, device, sequence_info_test=None):\n",
    "    \"\"\"Evaluate the model performance and return predictions with additional info\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    all_sequence_info = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_X, batch_y) in enumerate(test_loader):\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "\n",
    "            # Inverse transform predictions\n",
    "            pred_capacity = data_processor.capacity_scaler.inverse_transform(\n",
    "                outputs.cpu().numpy().reshape(-1, 1)\n",
    "            ).flatten()\n",
    "\n",
    "            actual_capacity = data_processor.capacity_scaler.inverse_transform(\n",
    "                batch_y.cpu().numpy().reshape(-1, 1)\n",
    "            ).flatten()\n",
    "\n",
    "            predictions.extend(pred_capacity)\n",
    "            actuals.extend(actual_capacity)\n",
    "            \n",
    "            # Store sequence information if available\n",
    "            if sequence_info_test is not None:\n",
    "                start_idx = batch_idx * test_loader.batch_size\n",
    "                end_idx = start_idx + len(batch_X)\n",
    "                all_sequence_info.extend(sequence_info_test[start_idx:end_idx])\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "\n",
    "    print(f\"Evaluation Metrics:\")\n",
    "    print(f\"MSE: {mse:.6f}\")\n",
    "    print(f\"MAE: {mae:.6f}\")\n",
    "    print(f\"RMSE: {rmse:.6f}\")\n",
    "    print(f\"R² Score: {r2:.6f}\")\n",
    "\n",
    "    return predictions, actuals, {'mse': mse, 'mae': mae, 'rmse': rmse, 'r2': r2}, all_sequence_info\n",
    "\n",
    "def get_all_predictions(model, data_loader, data_processor, device, sequence_info=None):\n",
    "    \"\"\"Get predictions for all data in the loader\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "    all_info = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_X, batch_y) in enumerate(data_loader):\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "\n",
    "            # Inverse transform predictions\n",
    "            pred_capacity = data_processor.capacity_scaler.inverse_transform(\n",
    "                outputs.cpu().numpy().reshape(-1, 1)\n",
    "            ).flatten()\n",
    "\n",
    "            actual_capacity = data_processor.capacity_scaler.inverse_transform(\n",
    "                batch_y.cpu().numpy().reshape(-1, 1)\n",
    "            ).flatten()\n",
    "\n",
    "            all_predictions.extend(pred_capacity)\n",
    "            all_actuals.extend(actual_capacity)\n",
    "            \n",
    "            # Store sequence information if available\n",
    "            if sequence_info is not None:\n",
    "                start_idx = batch_idx * data_loader.batch_size\n",
    "                end_idx = start_idx + len(batch_X)\n",
    "                all_info.extend(sequence_info[start_idx:end_idx])\n",
    "\n",
    "    return all_predictions, all_actuals, all_info\n",
    "\n",
    "def save_predictions_to_csv(predictions, actuals, sequence_info, filename='battery_predictions.csv'):\n",
    "    \"\"\"Save predictions and actual values to CSV file\"\"\"\n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'battery_id': [info['battery_id'] for info in sequence_info],\n",
    "        'cycle': [info['actual_cycle'] for info in sequence_info],\n",
    "        'actual_capacity': actuals,\n",
    "        'predicted_capacity': predictions,\n",
    "        'absolute_error': np.abs(np.array(actuals) - np.array(predictions)),\n",
    "        'relative_error_percent': (np.abs(np.array(actuals) - np.array(predictions)) / np.array(actuals)) * 100\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"✅ Predictions saved to {filename}\")\n",
    "    print(f\"📊 File contains {len(results_df)} predictions\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def plot_battery_degradation(combined_df):\n",
    "    \"\"\"Plot capacity degradation for all batteries\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for battery_id in combined_df['battery_id'].unique():\n",
    "        battery_data = combined_df[combined_df['battery_id'] == battery_id].sort_values('cycle')\n",
    "        plt.plot(battery_data['cycle'], battery_data['capacity'], label=battery_id, marker='o', markersize=2)\n",
    "\n",
    "    plt.xlabel('Cycle Number')\n",
    "    plt.ylabel('Capacity (Ah)')\n",
    "    plt.title('Battery Capacity Degradation - All Batteries')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Set output directory for CSV files\n",
    "    output_dir = '/content/drive/MyDrive/DL_Project'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    sequence_length = 20\n",
    "    hidden_size = 64\n",
    "    num_layers = 2\n",
    "    output_size = 1\n",
    "    batch_size = 32\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.001\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "\n",
    "    # Initialize data processor\n",
    "    processor = BatteryDataProcessor(sequence_length=sequence_length)\n",
    "\n",
    "    # Load real battery data from your directory\n",
    "    data_directory = '/content/drive/MyDrive/DL_Project/battery_data/5. Battery Data Set/1. BatteryAgingARC-FY08Q4'\n",
    "\n",
    "    print(\"Loading real battery data...\")\n",
    "    all_battery_data = processor.load_all_battery_files(data_directory)\n",
    "\n",
    "    if all_battery_data:\n",
    "        print(f\"Successfully loaded data from {len(all_battery_data)} batteries\")\n",
    "        combined_df = processor.combine_battery_data(all_battery_data)\n",
    "        plot_battery_degradation(combined_df)\n",
    "    else:\n",
    "        print(\"No real data loaded. Generating synthetic data...\")\n",
    "        combined_df = processor.prepare_synthetic_data(num_cycles=300)\n",
    "\n",
    "    print(f\"Final data shape: {combined_df.shape}\")\n",
    "    print(f\"Available columns: {combined_df.columns.tolist()}\")\n",
    "    print(f\"Batteries: {combined_df['battery_id'].unique()}\")\n",
    "\n",
    "    # Create sequences for LSTM (now returns sequence_info as well)\n",
    "    sequences, targets, sequence_info = processor.create_sequences(combined_df)\n",
    "    print(f\"Sequences shape: {sequences.shape}\")\n",
    "    print(f\"Targets shape: {targets.shape}\")\n",
    "\n",
    "    if len(sequences) == 0:\n",
    "        print(\"No sequences created. Check your data extraction.\")\n",
    "        return\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_tensor = torch.FloatTensor(sequences)\n",
    "    y_tensor = torch.FloatTensor(targets)\n",
    "\n",
    "    # Create dataset and split\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = int(val_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    # Split sequence_info accordingly\n",
    "    train_info = [sequence_info[i] for i in train_dataset.indices]\n",
    "    val_info = [sequence_info[i] for i in val_dataset.indices]\n",
    "    test_info = [sequence_info[i] for i in test_dataset.indices]\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    input_size = sequences.shape[2]\n",
    "    model = BatteryLSTM(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=output_size,\n",
    "        dropout_rate=0.3\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"Model architecture:\")\n",
    "    print(model)\n",
    "    print(f\"Input size: {input_size}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # Train model\n",
    "    trainer = BatteryTrainer(model, device)\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train(train_loader, val_loader, num_epochs, learning_rate)\n",
    "\n",
    "    # Plot training history\n",
    "    trainer.plot_training_history()\n",
    "\n",
    "    # Evaluate model on test set\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    test_predictions, test_actuals, test_metrics, test_sequence_info = evaluate_model(\n",
    "        model, test_loader, processor, device, test_info\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 📊 ONLY CREATE all_battery_predictions.csv\n",
    "    # --------------------------------------------------\n",
    "    print(\"\\n📈 Generating predictions for entire dataset...\")\n",
    "    \n",
    "    # Create data loader for entire dataset\n",
    "    full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Get predictions for all data\n",
    "    all_predictions, all_actuals, all_info = get_all_predictions(\n",
    "        model, full_loader, processor, device, sequence_info\n",
    "    )\n",
    "    \n",
    "    # Save ONLY all predictions to CSV in the specified directory\n",
    "    all_predictions_path = os.path.join(output_dir, 'all_battery_predictions.csv')\n",
    "    results_df = save_predictions_to_csv(all_predictions, all_actuals, all_info, all_predictions_path)\n",
    "    \n",
    "    # Display first few rows of the results\n",
    "    print(\"\\n📋 First 10 rows of all predictions:\")\n",
    "    print(results_df.head(10))\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 📊 ADDITIONAL PERFORMANCE VISUALIZATIONS\n",
    "    # --------------------------------------------------\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Use test set predictions for visualizations\n",
    "    predictions = np.array(test_predictions)\n",
    "    actuals = np.array(test_actuals)\n",
    "\n",
    "    # ---- Scatter plot: Predicted vs Actual ----\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x=actuals, y=predictions, alpha=0.7)\n",
    "    plt.plot([actuals.min(), actuals.max()], [actuals.min(), actuals.max()], 'r--', lw=2)\n",
    "    plt.xlabel(\"Actual Capacity (Ah)\")\n",
    "    plt.ylabel(\"Predicted Capacity (Ah)\")\n",
    "    plt.title(\"Predicted vs Actual Capacity\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Line plot: First N samples ----\n",
    "    N = 100  # You can adjust this number\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(actuals[:N], label='Actual', marker='o', markersize=3)\n",
    "    plt.plot(predictions[:N], label='Predicted', marker='x', markersize=3)\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Capacity (Ah)\")\n",
    "    plt.title(f\"Actual vs Predicted Capacity (First {N} Test Samples)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Residual plot ----\n",
    "    residuals = actuals - predictions\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(residuals, kde=True, color='skyblue')\n",
    "    plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "    plt.title(\"Residual Distribution\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Metrics Summary Table ----\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Metric\": [\"MAE\", \"RMSE\", \"R²\", \"MSE\"],\n",
    "        \"Value\": [test_metrics['mae'], test_metrics['rmse'], test_metrics['r2'], test_metrics['mse']]\n",
    "    })\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 1.5))\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=metrics_df.values, colLabels=metrics_df.columns,\n",
    "                     loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2)\n",
    "    plt.title(\"Model Performance Summary\", pad=10)\n",
    "    plt.show()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 📉 Original comparison plots (optional)\n",
    "    # --------------------------------------------------\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(test_actuals, label='Actual Capacity', alpha=0.7)\n",
    "    plt.plot(test_predictions, label='Predicted Capacity', alpha=0.7)\n",
    "    plt.xlabel('Test Samples')\n",
    "    plt.ylabel('Capacity (Ah)')\n",
    "    plt.title('Predictions vs Actual (Test Set)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for battery_id in combined_df['battery_id'].unique():\n",
    "        battery_data = combined_df[combined_df['battery_id'] == battery_id].sort_values('cycle')\n",
    "        plt.plot(battery_data['cycle'], battery_data['capacity'], label=battery_id, alpha=0.7)\n",
    "    plt.xlabel('Cycle Number')\n",
    "    plt.ylabel('Capacity (Ah)')\n",
    "    plt.title('Battery Capacity Degradation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(trainer.train_losses, label='Training Loss')\n",
    "    plt.plot(trainer.val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save model to the output directory\n",
    "    model_path = os.path.join(output_dir, 'battery_lstm_model.pth')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'processor_scaler': processor.scaler,\n",
    "        'processor_capacity_scaler': processor.capacity_scaler,\n",
    "        'sequence_length': sequence_length,\n",
    "        'input_size': input_size\n",
    "    }, model_path)\n",
    "\n",
    "    print(\"✅ Model and visualizations complete!\")\n",
    "    print(f\"📁 All files saved to: {output_dir}\")\n",
    "    print(f\"📊 CSV files created:\")\n",
    "    print(f\"   - all_battery_predictions.csv (all data)\")  # Only this file is created\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
